+ exec gosu vibecode scripts/start --hot
Installing dependencies and generating Prisma client...
[0.03ms] ".env"
bun install v1.2.19 (aad3abea)

$ prisma generate
Environment variables loaded from .env
Prisma schema loaded from prisma/schema.prisma

âœ” Generated Prisma Client (v6.17.1) to ./generated/prisma in 484ms

Start by importing your Prisma Client (See: https://pris.ly/d/importing-client)

Tip: Interested in query caching in just a few lines of code? Try Accelerate today! https://pris.ly/tip-3-accelerate


Checked 769 installs across 711 packages (no changes) [1.98s]
Starting server in dev mode with hot reload...
$ NODE_ENV=development bun run --hot src/index.ts
Failed to find Response internal state key
âœ… Environment variables validated successfully
ğŸ” [Auth] Initializing Better Auth...
âœ… [Auth] Better Auth initialized
ğŸ”— [Auth] Base URL: https://preview-jsbubptojukj.share.sandbox.dev
ğŸŒ [Auth] Trusted origins: vibecode://, http://localhost:3000, https://preview-jsbubptojukj.share.sandbox.dev
ğŸ”§ Initializing Hono application...
ğŸ” Mounting Better Auth handler at /api/auth/*
ğŸ“ Serving static files from uploads/ directory
ğŸ¤– Mounting companion routes at /api/companion
ğŸ’¬ Mounting chat routes at /api/chat
ğŸ¯ Mounting bond routes at /api/bond
âš™ï¸  Mounting settings routes at /api/settings
âš™ï¸  Starting server...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ Environment: development
ğŸš€ Server is running on port 3000
ğŸ”— Base URL: http://localhost:3000
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“š Available endpoints:
  ğŸ” Auth:       /api/auth/*
  ğŸ¤– Companion:  GET/POST/PUT /api/companion
  ğŸ’¬ Chat:       GET/POST /api/chat
  ğŸ¯ Bond:       GET /api/bond, POST /api/bond/check-in, /api/bond/gratitude, /api/bond/goal
  âš™ï¸  Settings:   GET/PUT /api/settings
  ğŸ’š Health:     GET /health
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

<-- GET /api/auth/get-session
--> GET /api/auth/get-session [32m200[0m 11ms
<-- GET /api/companion
--> GET /api/companion [33m404[0m 6ms
<-- GET /api/auth/get-session
--> GET /api/auth/get-session [32m200[0m 4ms
<-- POST /api/companion
--> POST /api/companion [32m200[0m 11ms
<-- GET /api/chat
--> GET /api/chat [32m200[0m 4ms
<-- GET /api/companion
--> GET /api/companion [32m200[0m 2ms
<-- GET /api/companion
<-- GET /api/bond
--> GET /api/companion [32m200[0m 4ms
--> GET /api/bond [32m200[0m 19ms
<-- POST /api/bond/check-in
[AI] Error generating check-in response: 14 |   constructor({
15 |     name: name14,
16 |     message,
17 |     cause
18 |   }) {
19 |     super(message);
         ^
AI_APICallError: Incorrect API key provided: ''. You can find your API key at https://platform.openai.com/account/api-keys.
      cause: undefined,
        url: "https://api.openai.com/v1/responses",
 requestBodyValues: {
  model: "gpt-4o-mini",
  input: [
    [Object ...]
  ],
  temperature: 0.9,
  top_p: undefined,
  max_output_tokens: undefined,
  conversation: undefined,
  max_tool_calls: undefined,
  metadata: undefined,
  parallel_tool_calls: undefined,
  previous_response_id: undefined,
  store: undefined,
  user: undefined,
  instructions: undefined,
  service_tier: undefined,
  include: undefined,
  prompt_cache_key: undefined,
  prompt_cache_retention: undefined,
  safety_identifier: undefined,
  top_logprobs: undefined,
  truncation: undefined,
  tools: undefined,
  tool_choice: undefined,
},
 statusCode: 401,
 responseHeaders: {
  "alt-svc": "h3=\":443\"; ma=86400",
  "cf-cache-status": "DYNAMIC",
  "cf-ray": "9a57d210fb62681e-SEA",
  connection: "keep-alive",
  "content-length": "231",
  "content-type": "application/json",
  date: "Fri, 28 Nov 2025 06:31:07 GMT",
  "openai-processing-ms": "18",
  "openai-version": "2020-10-01",
  server: "cloudflare",
  "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
  "www-authenticate": "Bearer realm=\"OpenAI API\"",
  "x-content-type-options": "nosniff",
  "x-envoy-upstream-service-time": "20",
  "x-request-id": "req_19a2f28192404e8fbca75db9d58ce9b0",
  "set-cookie": "_cfuvid=fppWd9mopeanhV8kKwCNUcabkMCsPFrGJIfGtJjkBoI-1764311467791-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None",
},
 responseBody: "{\n  \"error\": {\n    \"message\": \"Incorrect API key provided: ''. You can find your API key at https://platform.openai.com/account/api-keys.\",\n    \"type\": \"invalid_request_error\",\n    \"param\": null,\n    \"code\": \"invalid_api_key\"\n  }\n}",
 isRetryable: false,
       data: {
  error: [Object ...],
},
 vercel.ai.error: true,
 vercel.ai.error.AI_APICallError: true,

      at new _AISDKError (/home/user/workspace/backend/node_modules/@ai-sdk/provider/dist/index.mjs:19:5)

--> POST /api/bond/check-in [32m200[0m 170ms
<-- GET /api/bond
<-- GET /api/companion
--> GET /api/companion [32m200[0m 2ms
--> GET /api/bond [32m200[0m 5ms
<-- POST /api/bond/gratitude
--> POST /api/bond/gratitude [32m200[0m 308ms
<-- GET /api/companion
<-- GET /api/bond
--> GET /api/companion [32m200[0m 3ms
--> GET /api/bond [32m200[0m 4ms
<-- POST /api/bond/goal
--> POST /api/bond/goal [32m200[0m 13ms
<-- GET /api/companion
<-- GET /api/bond
--> GET /api/companion [32m200[0m 5ms
--> GET /api/bond [32m200[0m 5ms
<-- GET /api/companion
<-- GET /api/settings
--> GET /api/companion [32m200[0m 3ms
--> GET /api/settings [32m200[0m 3ms
<-- PUT /api/settings
--> PUT /api/settings [32m200[0m 4ms
<-- GET /api/settings
--> GET /api/settings [32m200[0m 2ms
<-- PUT /api/settings
--> PUT /api/settings [32m200[0m 4ms
<-- GET /api/settings
--> GET /api/settings [32m200[0m 2ms
<-- GET /api/auth/get-session
--> GET /api/auth/get-session [32m200[0m 4ms
<-- GET /api/companion
--> GET /api/companion [32m200[0m 3ms
<-- GET /api/companion
<-- GET /api/chat
--> GET /api/companion [32m200[0m 3ms
--> GET /api/chat [32m200[0m 3ms
<-- GET /api/companion
<-- GET /api/chat
--> GET /api/companion [32m200[0m 9ms
--> GET /api/chat [32m200[0m 9ms
<-- GET /api/companion
<-- GET /api/chat
--> GET /api/companion [32m200[0m 7ms
--> GET /api/chat [32m200[0m 8ms
<-- GET /api/companion
<-- GET /api/chat
--> GET /api/companion [32m200[0m 33ms
--> GET /api/chat [32m200[0m 17ms
<-- GET /api/chat
<-- GET /api/companion
--> GET /api/chat [32m200[0m 15ms
--> GET /api/companion [32m200[0m 30ms
